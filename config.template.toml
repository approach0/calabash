[environment]
scripts = ./scripts
job_dir = ./jobs
admin_name = admin
node_prefix = calabash

[iaas]
#providers = [linode, ucloud]
providers = [ucloud]

  [iaas.linode]
  token = ___
  docker_mirror = https://docker.io
  # docker mirror alternatives: https://hub-mirror.c.163.com
  docker_image = ga6840/linode-cli:latest
  docker_registry_user = ___
  docker_registry_pass = ___

    [iaas.linode.config_1]
    region = ap-southeast
    specs = 'g6-nanode-1'
    distro = linode/debian10
    ssh_port = 8921
    password = ___

  [iaas.ucloud]
  pubkey = ___
  prikey = ___
  docker_mirror = https://uhub.service.ucloud.cn
  docker_image = ga6840/ucloud-cli:latest
  docker_registry_user = ___
  docker_registry_pass = ___

    [iaas.ucloud.config_1]
    region = cn-gd
    specs = 1cpu-1gb-1mb
    distro = 'Debian_9'
    ssh_port = 22
    password = ___

[network]

  [network.approach0]
  driver = overlay

[node_usage]
  [node_usage.host_corpus]
  labels = [
    'host_corpus=true'
  ]

  [node_usage.host_indexer]
  labels = [
    'host_indexer=true',
  ]
  install_hooks = [
    'install_fuse',
    'vdisk_producer_daemon 1K'
  ]

  [node_usage.host_searchd]
  labels = [
    'host_searchd=true'
  ]
  install_hooks = [
    'install_fuse',
    'vdisk_consume_daemon'
  ]

[service]
bootstrap_service = calabash

# See https://docs.docker.com/engine/reference/commandline/service_create
print_arguments = [
  mesh_replicas,
  mesh_sharding,
  network,
  portmap,
  max_per_node, # maximum number of this type of services per node
  restart_condition,
  constraints,
  docker_image,
  configs,
  mounts,
  docker_exec
]

  [service.calabash]
  portmap = '80:8964'
  constraints = [
    'node.role==manager'
  ]
  docker_image = ga6840/calabash:latest
  config_bind = [
    'path:calabash_config:/code/calabash/config.toml'
  ]
  config_source = [
    '/tmp/bootstrap.config.toml'
  ]
  mounts = [
    'type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock',
    'type=bind,src=/var/log,dst=/mnt/log,ro=false',
  ]
  docker_exec = node ./jobd/jobd.js --config ./config.toml | tee -a /mnt/log/calabash.log

  [service.hello]
  portmap = 'published=3389,target=8080,mode=ingress' # servcie mesh with only shard#1 publishing port
  mesh_replicas = 2
  mesh_sharding = 2

  #portmap = 'published=3389,target=8080,mode=host' # different IP different shard
  #mesh_replicas=1
  #mesh_sharding=2

  #portmap = 'published=3389,target=8080,mode=ingress' # round robin-ing hosts
  #mesh_replicas=2
  #mesh_sharding=1

  docker_image = ga6840/hello-httpd:latest
  config_bind = [
    'text:hello_entrypoint:/tmp/entrypoint.sh'
  ]
  config_source = [
    '''
    node /code/hello.js \$(hostname) shard#\$@
    '''
  ]
  docker_exec = sh /tmp/entrypoint.sh \$shard

  [service.corpus]
  network = approach0
  mesh_sharding = 3
  max_per_node = 1
  mounts = [
    'type=volume,src=corpus_vol,dst=/data',
  ]
  constraints = [
    'node.labels.host_corpus==true'
  ]
  docker_image = ga6840/rsyncd

  config_bind = [
    'text:corpus_entrypoint:/tmp/entrypoint.sh'
  ]
  config_source = [
    '''
    rsync --daemon --verbose --config=/tmp/rsyncd.conf

    src=\$1
    while true; do
      for dst in corpus corpus-shard{2..3}; do
        if [ "\$src" != "\$dst" ]; then
          rsync -zauv --progress /data/ rsync://\$dst/root/
        fi
      done
      sleep 16
    done
    '''
  ]
  docker_exec = bash /tmp/entrypoint.sh \$servID

  [service.crawler]
  mesh_sharding = 3
  max_per_node = 1
  mounts = [
    'type=volume,src=corpus_vol,dst=/data',
  ]
  constraints = [
    'node.labels.host_corpus==true'
  ]
  docker_image = ga6840/a0:latest
  config_bind = [
    'text:crawler_entrypoint:/tmp/entrypoint.sh'
  ]
  config_source = [
    '''
    shard=\$1
    export PATH=\"\$PATH:\$(pwd)/demo/crawler\"
    cd /data

    while true; do
      case \$shard in
      1)
        crawler-math.stackexchange.com.py  --begin-page     1 --end-page  1000
        crawler-math.stackexchange.com.py  --begin-page  1001 --end-page  7000
      ;;

      2)
        crawler-math.stackexchange.com.py  --begin-page  7001 --end-page 17000
        crawler-math.stackexchange.com.py  --begin-page 17001 --end-page 27000
        crawler-math.stackexchange.com.py  --begin-page 17001 --end-page 27000
      ;;

      3)
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 3
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 4
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 5
      ;;

      4)
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 6
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 7
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 123
        crawler-artofproblemsolving.com.py  -n 0 -o 3650 -c 163
      ;;
      esac

      echo 'Start over ...'
      sleep 32
    done
    '''
  ]
  docker_exec = bash /tmp/entrypoint.sh \$shard

  [service.indexer]
  network = approach0
  mesh_sharding = 2
  max_per_node = 1
  mounts = [
    'type=bind,src=/var/tmp/vdisk,dst=/mnt/vdisk'
  ]
  constraints = [
    'node.labels.host_indexer==true'
  ]
  docker_image = ga6840/a0:latest

  config_bind = [
    'text:indexer_entrypoint:/tmp/entrypoint.sh'
  ]
  config_source = [
    '''
    (flock 100; indexer.out -z -o /mnt/vdisk/mnt/; sync ) 100>/mnt/vdisk/vdisk.lock
    '''
  ]
  docker_exec = bash /tmp/entrypoint.sh

  [service.feeder]
  network = approach0
  mounts = [
    'type=volume,src=corpus_vol,dst=/data',
  ]
  constraints = [
    'node.labels.host_corpus==true'
  ]
  docker_image = ga6840/a0:latest

  config_bind = [
    'text:feeder_entrypoint:/tmp/entrypoint.sh'
  ]
  config_source = [
    '''
    ./indexerd/scripts/json-feeder.py --corpus-path /data \
      --indexd-url http://indexer:8934/index \
      --indexd-url http://indexer-shard2:8934/index \
    '''
  ]
  docker_exec = bash /tmp/entrypoint.sh

  [service.index_syncd]
  network = approach0
  mesh_sharding = 2
  max_per_node = 1
  mounts = [
    'type=bind,src=/var/tmp/vdisk,dst=/mnt/vdisk'
  ]
  constraints = [
    'node.labels.host_indexer==true'
  ]
  docker_image = ga6840/rsyncd
  docker_exec = ''

  [service.searchd]
  network = approach0
  mesh_sharding = 2
  mesh_replicas = 2
  max_per_node = 1
  mounts = [
    'type=bind,src=/var/tmp/vdisk,dst=/mnt/vdisk'
  ]
  constraints = [
    'node.labels.host_searchd==true'
  ]
  docker_image = ga6840/a0:latest

  config_bind = [
    'text:search_entrypoint:/tmp/entrypoint.sh'
  ]
  config_source = [
    '''
    shard=\$1
    if [ \$shard -eq 1 ]; then
      rsync -zuv --progress rsync://index_syncd/root/vdisk.*.img .
    else
      rsync -zuv --progress rsync://index_syncd-shard\$shard/root/vdisk.*.img .
    fi

    /usr/sbin/sshd -D -e
    '''
  ]
  docker_exec = bash /tmp/entrypoint.sh \$shard
